{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dca8c1f9765a48d0ada22ba49859ed5d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Face Recognition Assignment\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b902bce3346a456a880d101506315e20",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<span style=\"font-size: 20px;\">For a neater, properly organized and easy-maintained assignment, this section covers all non-CNN related code, including:</span>\n",
    "\n",
    "- **Importing Libraries**: Code for importing required Python libraries (e.g., pandas, numpy).\n",
    "- **Dataset Loading**: Code for loading the dataset from a file or source.\n",
    "- **Dataset Separation**: Code for splitting the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1b6cbf87508344da9fda15d7d1dbb6cc",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "521f350884db4ca3bf9bb64949582f76",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Imoprt Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "cell_id": "96a70bede92648558b009b2db975d4d5",
    "deepnote_cell_type": "code",
    "execution_context_id": "cef2901b-8efd-4d32-bd08-1c05cb27a56c",
    "execution_millis": 3279,
    "execution_start": 1746900707769,
    "source_hash": "8ff451cd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import kagglehub\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ae76a63ce8f84404ac9dfddd04f21cb8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "673f9bb8226344648ea202bfd7fd32d7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "cell_id": "a36b823d3f3249b5a91a047d3df66c13",
    "deepnote_cell_type": "code",
    "execution_context_id": "cef2901b-8efd-4d32-bd08-1c05cb27a56c",
    "execution_millis": 1,
    "execution_start": 1746900715933,
    "source_hash": "1c0b77a5"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    path = kagglehub.dataset_download(\"dmitrybabko/speech-emotion-recognition-en\")+\"/Crema\"\n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(\"Download CREMA dataset.\")\n",
    "    \n",
    "    X_time = []\n",
    "    X_freq = []\n",
    "    y = []\n",
    "    audio_files = sorted(glob(f\"{path}/*.wav\"))\n",
    "    print(f'Audio Files Number: {len(audio_files)}')\n",
    "    \n",
    "    for audio_file in audio_files:\n",
    "        audio, sr = librosa.load(audio_file)\n",
    "        audio_fixed = librosa.util.fix_length(audio, size=int(5 * sr))\n",
    "        \n",
    "        zcr = librosa.feature.zero_crossing_rate(audio_fixed, frame_length=2048, hop_length=512)\n",
    "        energy = librosa.feature.rms(y=audio_fixed, frame_length=2048, hop_length=512)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio_fixed, sr=sr)\n",
    "        # mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        X_time.append(np.vstack((zcr, energy)))\n",
    "        X_freq.append(mel_spec)\n",
    "        y.append(audio_file.split(\"_\")[2])\n",
    "        \n",
    "    return X_time, X_freq, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0ad7dc216a2d414a88bc68b8bce9e897",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2142dfc1dcfa44f0a5c5c6f33c1a3f2d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Dataset Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "cell_id": "fa08c5e1bbab459a910db1376930d1ef",
    "deepnote_cell_type": "code",
    "execution_context_id": "cef2901b-8efd-4d32-bd08-1c05cb27a56c",
    "execution_millis": 13,
    "execution_start": 1746900719319,
    "source_hash": "cc1d7507"
   },
   "outputs": [],
   "source": [
    "def separate_dataset():\n",
    "    # Time Domain Split\n",
    "    X_time, X_freq, y = load_dataset()\n",
    "    X_time_train_val, X_time_test, y_time_train_val, y_time_test = train_test_split(X_time, y, train_size=0.7, stratify=y, random_state=SEED)\n",
    "    X_time_train, X_time_val, y_time_train, y_time_val = train_test_split(X_time_train_val, y_time_train_val, train_size=0.95, stratify=y_time_train_val, random_state=SEED)\n",
    "    # Frequency Domain Split\n",
    "    X_freq_train_val, X_freq_test, y_freq_train_val, y_freq_test = train_test_split(X_freq, y, train_size=0.7, stratify=y, random_state=SEED)\n",
    "    X_freq_train, X_freq_val, y_freq_train, y_freq_val = train_test_split(X_freq_train_val, y_freq_train_val, train_size=0.95, stratify=y_freq_train_val, random_state=SEED)\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    X_time_train = np.array(X_time_train)\n",
    "    y_time_train = np.array(y_time_train)\n",
    "    X_freq_train = np.array(X_freq_train)\n",
    "    y_freq_train = np.array(y_freq_train)\n",
    "\n",
    "    X_time_val = np.array(X_time_val)\n",
    "    y_time_val = np.array(y_time_val)\n",
    "    X_freq_val = np.array(X_freq_val)\n",
    "    y_freq_val = np.array(y_freq_val)\n",
    "\n",
    "    X_time_test = np.array(X_time_test)\n",
    "    y_time_test = np.array(y_time_test)\n",
    "    X_freq_test = np.array(X_freq_test)\n",
    "    y_freq_test = np.array(y_freq_test)\n",
    "\n",
    "    print(f'Training Set: time domain shape {X_time_train.shape}, frequency domain shape {X_freq_train.shape}')\n",
    "    print(f'Validation Set: time domain shape {X_time_val.shape}, frequency domain shape {X_freq_val.shape}')\n",
    "    print(f'Test Set: time domain shape {X_time_test.shape}, frequency domain shape {X_freq_test.shape}')\n",
    "    \n",
    "    return (X_time_train, X_freq_train, X_time_val, X_freq_val, X_time_test, X_freq_test, \n",
    "    y_time_train, y_freq_train, y_time_val, y_freq_val, y_time_test, y_freq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "cell_id": "4d3a45e23d6a4011b72f77b4e8c12ec3",
    "deepnote_cell_type": "code",
    "execution_context_id": "cef2901b-8efd-4d32-bd08-1c05cb27a56c",
    "execution_millis": 229197,
    "execution_start": 1746900750369,
    "source_hash": "44359dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Audio Files Number: 7442\n",
      "Training Set: time domain shape (4948, 2, 216), frequency domain shape (4948, 128, 216)\n",
      "Validation Set: time domain shape (261, 2, 216), frequency domain shape (261, 128, 216)\n",
      "Test Set: time domain shape (2233, 2, 216), frequency domain shape (2233, 128, 216)\n"
     ]
    }
   ],
   "source": [
    "(X_time_train, X_freq_train, X_time_val, X_freq_val, X_time_test, X_freq_test, \n",
    " y_time_train, y_freq_train, y_time_val, y_freq_val, y_time_test, y_freq_test) = separate_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "9f4e87169cbc446baf3cf131bca59126",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
